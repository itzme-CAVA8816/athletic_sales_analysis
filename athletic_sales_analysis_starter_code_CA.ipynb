{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries and Dependencies\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Combine and Clean the Data\n",
    "#### Import CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV files into DataFrames.\n",
    "athletic_sales_2020 = pd.read_csv('athletic_sales_2020.csv')\n",
    "athletic_sales_2021 = pd.read_csv('athletic_sales_2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         retailer  retailer_id invoice_date     region         state  \\\n",
      "0     Foot Locker      1185732     1/1/2020  Northeast      New York   \n",
      "1     Foot Locker      1185732     1/1/2020  Northeast  Pennsylvania   \n",
      "2     Foot Locker      1185732     1/1/2020  Northeast  Pennsylvania   \n",
      "3     Foot Locker      1185732     1/1/2020  Northeast      New York   \n",
      "4     Foot Locker      1185732     1/1/2020  Northeast  Pennsylvania   \n",
      "...           ...          ...          ...        ...           ...   \n",
      "1292    West Gear      1128299   12/30/2020       West    California   \n",
      "1293    West Gear      1128299   12/30/2020       West    California   \n",
      "1294       Kohl's      1189833   12/30/2020    Midwest     Minnesota   \n",
      "1295       Kohl's      1189833   12/30/2020    Midwest     Minnesota   \n",
      "1296    West Gear      1128299   12/30/2020       West    California   \n",
      "\n",
      "               city                  product  price_per_unit  units_sold  \\\n",
      "0          New York    Men's Street Footwear              50        1200   \n",
      "1      Philadelphia          Women's Apparel              68          83   \n",
      "2      Philadelphia          Women's Apparel              75         275   \n",
      "3          New York    Men's Street Footwear              34         384   \n",
      "4      Philadelphia          Women's Apparel              53          83   \n",
      "...             ...                      ...             ...         ...   \n",
      "1292  San Francisco          Women's Apparel              72         203   \n",
      "1293  San Francisco          Women's Apparel              80         700   \n",
      "1294    Minneapolis  Women's Street Footwear              41         119   \n",
      "1295    Minneapolis  Women's Street Footwear              45         475   \n",
      "1296  San Francisco          Women's Apparel              62         245   \n",
      "\n",
      "      total_sales  operating_profit sales_method  \n",
      "0          600000         300000.00     In-store  \n",
      "1            5644           2426.92       Online  \n",
      "2          206250          61875.00       Outlet  \n",
      "3           13056           6789.12       Outlet  \n",
      "4            4399           1407.68       Outlet  \n",
      "...           ...               ...          ...  \n",
      "1292        14616           3946.32       Online  \n",
      "1293       560000          84000.00       Outlet  \n",
      "1294         4879           2878.61       Online  \n",
      "1295       213750          96187.50       Outlet  \n",
      "1296        15190           2886.10       Outlet  \n",
      "\n",
      "[1297 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the 2020 sales DataFrame\n",
    "print(athletic_sales_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         retailer  retailer_id invoice_date     region         state  \\\n",
      "0       West Gear      1128299       1/1/21       West    California   \n",
      "1       West Gear      1128299       1/1/21       West    California   \n",
      "2          Kohl's      1189833       1/1/21    Midwest       Montana   \n",
      "3          Kohl's      1189833       1/1/21    Midwest       Montana   \n",
      "4       West Gear      1128299       1/1/21       West    California   \n",
      "...           ...          ...          ...        ...           ...   \n",
      "8341  Foot Locker      1185732     12/31/21  Northeast  Pennsylvania   \n",
      "8342  Foot Locker      1185732     12/31/21  Northeast  Pennsylvania   \n",
      "8343       Amazon      1185732     12/31/21  Northeast         Maine   \n",
      "8344       Amazon      1185732     12/31/21  Northeast         Maine   \n",
      "8345  Foot Locker      1185732     12/31/21  Northeast  Pennsylvania   \n",
      "\n",
      "               city                  product  price_per_unit  units_sold  \\\n",
      "0     San Francisco  Men's Athletic Footwear              65         750   \n",
      "1     San Francisco  Men's Athletic Footwear              51         233   \n",
      "2          Billings            Men's Apparel              50         275   \n",
      "3          Billings            Men's Apparel              47          77   \n",
      "4     San Francisco  Men's Athletic Footwear              64         225   \n",
      "...             ...                      ...             ...         ...   \n",
      "8341   Philadelphia            Men's Apparel              63          47   \n",
      "8342   Philadelphia            Men's Apparel              46          56   \n",
      "8343       Portland            Men's Apparel              52          36   \n",
      "8344       Portland            Men's Apparel              55         125   \n",
      "8345   Philadelphia            Men's Apparel              70         175   \n",
      "\n",
      "      total_sales  operating_profit sales_method  \n",
      "0          487500         121875.00       Outlet  \n",
      "1           11883           3208.41       Outlet  \n",
      "2          137500          82500.00       Outlet  \n",
      "3            3619           2714.25       Online  \n",
      "4           14400           5184.00       Online  \n",
      "...           ...               ...          ...  \n",
      "8341         2961           1362.06       Online  \n",
      "8342         2576           1004.64       Outlet  \n",
      "8343         1872            692.64       Online  \n",
      "8344        68750          17187.50       Outlet  \n",
      "8345       122500          42875.00       Outlet  \n",
      "\n",
      "[8346 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the 2021 sales DataFrame\n",
    "print( athletic_sales_2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the data types of each DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retailer             object\n",
      "retailer_id           int64\n",
      "invoice_date         object\n",
      "region               object\n",
      "state                object\n",
      "city                 object\n",
      "product              object\n",
      "price_per_unit        int64\n",
      "units_sold            int64\n",
      "total_sales           int64\n",
      "operating_profit    float64\n",
      "sales_method         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check the 2020 sales data types.\n",
    "print(athletic_sales_2020.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retailer             object\n",
      "retailer_id           int64\n",
      "invoice_date         object\n",
      "region               object\n",
      "state                object\n",
      "city                 object\n",
      "product              object\n",
      "price_per_unit        int64\n",
      "units_sold            int64\n",
      "total_sales           int64\n",
      "operating_profit    float64\n",
      "sales_method         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check the 2021 sales data types.\n",
    "print(athletic_sales_2021.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the sales data by rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the 2020 and 2021 sales DataFrames on the rows and reset the index.\n",
    "sales_data = pd.concat([athletic_sales_2020, athletic_sales_2021]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retailer            0\n",
      "retailer_id         0\n",
      "invoice_date        0\n",
      "region              0\n",
      "state               0\n",
      "city                0\n",
      "product             0\n",
      "price_per_unit      0\n",
      "units_sold          0\n",
      "total_sales         0\n",
      "operating_profit    0\n",
      "sales_method        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if any values are null.\n",
    "print(sales_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retailer             object\n",
      "retailer_id           int64\n",
      "invoice_date         object\n",
      "region               object\n",
      "state                object\n",
      "city                 object\n",
      "product              object\n",
      "price_per_unit        int64\n",
      "units_sold            int64\n",
      "total_sales           int64\n",
      "operating_profit    float64\n",
      "sales_method         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check the data type of each column\n",
    "print(sales_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data \"1/1/21\" doesn't match format \"%m/%d/%Y\", at position 358. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/calvarez/Downloads/athletic_sales_analysis_starter_code_updated.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/calvarez/Downloads/athletic_sales_analysis_starter_code_updated.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Convert the \"invoice_date\" to a datetime datatype\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/calvarez/Downloads/athletic_sales_analysis_starter_code_updated.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sales_data[\u001b[39m'\u001b[39m\u001b[39minvoice_date\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mto_datetime(sales_data[\u001b[39m'\u001b[39;49m\u001b[39minvoice_date\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/tools/datetimes.py:1108\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1106\u001b[0m             result \u001b[39m=\u001b[39m arg\u001b[39m.\u001b[39mtz_localize(\u001b[39m\"\u001b[39m\u001b[39mutc\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1107\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, ABCSeries):\n\u001b[0;32m-> 1108\u001b[0m     cache_array \u001b[39m=\u001b[39m _maybe_cache(arg, \u001b[39mformat\u001b[39;49m, cache, convert_listlike)\n\u001b[1;32m   1109\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m cache_array\u001b[39m.\u001b[39mempty:\n\u001b[1;32m   1110\u001b[0m         result \u001b[39m=\u001b[39m arg\u001b[39m.\u001b[39mmap(cache_array)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/tools/datetimes.py:254\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[0;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[1;32m    252\u001b[0m unique_dates \u001b[39m=\u001b[39m unique(arg)\n\u001b[1;32m    253\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(unique_dates) \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(arg):\n\u001b[0;32m--> 254\u001b[0m     cache_dates \u001b[39m=\u001b[39m convert_listlike(unique_dates, \u001b[39mformat\u001b[39;49m)\n\u001b[1;32m    255\u001b[0m     \u001b[39m# GH#45319\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/tools/datetimes.py:488\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[39m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmixed\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 488\u001b[0m     \u001b[39mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[39mformat\u001b[39;49m, exact, errors)\n\u001b[1;32m    490\u001b[0m result, tz_parsed \u001b[39m=\u001b[39m objects_to_datetime64ns(\n\u001b[1;32m    491\u001b[0m     arg,\n\u001b[1;32m    492\u001b[0m     dayfirst\u001b[39m=\u001b[39mdayfirst,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    496\u001b[0m     allow_object\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    497\u001b[0m )\n\u001b[1;32m    499\u001b[0m \u001b[39mif\u001b[39;00m tz_parsed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m     \u001b[39m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    501\u001b[0m     \u001b[39m# is in UTC\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/tools/datetimes.py:519\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_array_strptime_with_fallback\u001b[39m(\n\u001b[1;32m    509\u001b[0m     arg,\n\u001b[1;32m    510\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    514\u001b[0m     errors: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    515\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Index:\n\u001b[1;32m    516\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[39m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     result, timezones \u001b[39m=\u001b[39m array_strptime(arg, fmt, exact\u001b[39m=\u001b[39;49mexact, errors\u001b[39m=\u001b[39;49merrors, utc\u001b[39m=\u001b[39;49mutc)\n\u001b[1;32m    520\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(tz \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m tz \u001b[39min\u001b[39;00m timezones):\n\u001b[1;32m    521\u001b[0m         \u001b[39mreturn\u001b[39;00m _return_parsed_timezone_results(result, timezones, utc, name)\n",
      "File \u001b[0;32mstrptime.pyx:534\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:355\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: time data \"1/1/21\" doesn't match format \"%m/%d/%Y\", at position 358. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "# Convert the \"invoice_date\" to a datetime datatype\n",
    "sales_data['invoice_date'] = pd.to_datetime(sales_data['invoice_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'invoive_date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3792\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'invoive_date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/calvarez/Downloads/athletic_sales_analysis_starter_code_updated.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/calvarez/Downloads/athletic_sales_analysis_starter_code_updated.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Confirm that the \"invoice_date\" data type has been changed.\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/calvarez/Downloads/athletic_sales_analysis_starter_code_updated.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(sales_data[\u001b[39m\"\u001b[39;49m\u001b[39minvoive_date\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'invoive_date'"
     ]
    }
   ],
   "source": [
    "# Confirm that the \"invoice_date\" data type has been changed.\n",
    "print(sales_data[\"invoive_date\"].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Determine which Region Sold the Most Products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `groupby`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       region       state           city  Total_Products_Sold\n",
      "21  Northeast    New York       New York               111954\n",
      "33      South       Texas        Houston                90322\n",
      "44       West  California  San Francisco                85478\n",
      "43       West  California    Los Angeles                76384\n",
      "34  Southeast     Florida          Miami                73135\n"
     ]
    }
   ],
   "source": [
    "# Show the number products sold for region, state, and city.\n",
    "# Rename the sum to \"Total_Products_Sold\".\n",
    "# Show the top 5 results.\n",
    "region_sales = sales_data.groupby(['region', 'state', 'city'])['units_sold'].sum().reset_index()\n",
    "region_sales.rename(columns={'units_sold': 'Total_Products_Sold'}, inplace=True)\n",
    "print(region_sales.nlargest(5, 'Total_Products_Sold'))                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `pivot_table`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Total_Products_Sold\n",
      "region    state      city                              \n",
      "Northeast New York   New York                    111954\n",
      "South     Texas      Houston                      90322\n",
      "West      California San Francisco                85478\n",
      "                     Los Angeles                  76384\n",
      "Southeast Florida    Miami                        73135\n"
     ]
    }
   ],
   "source": [
    "# Show the number products sold for region, state, and city.\n",
    "# Rename the \"units_sold\" column to \"Total_Products_Sold\"\n",
    "# Show the top 5 results.\n",
    "region_sales_pivot = sales_data.pivot_table(index=['region', 'state', 'city'], values='units_sold', aggfunc='sum')\n",
    "region_sales_pivot.rename(columns={'units_sold': 'Total_Products_Sold'}, inplace=True)\n",
    "print(region_sales_pivot.nlargest(5, 'Total_Products_Sold'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Determine which Region had the Most Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `groupby`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       region           state           city  Total Sales\n",
      "21  Northeast        New York       New York     39801235\n",
      "44       West      California  San Francisco     33973228\n",
      "34  Southeast         Florida          Miami     31600863\n",
      "39  Southeast  South Carolina     Charleston     29285637\n",
      "35  Southeast         Florida        Orlando     27682851\n"
     ]
    }
   ],
   "source": [
    "# Show the total sales for the products sold for each region, state, and city.\n",
    "# Rename the \"total_sales\" column to \"Total Sales\"\n",
    "# Show the top 5 results.\n",
    "region_sales = sales_data.groupby(['region', 'state', 'city'])['total_sales'].sum().reset_index()\n",
    "region_sales.rename(columns={'total_sales': 'Total Sales'}, inplace=True)\n",
    "print(region_sales.nlargest(5, 'Total Sales'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `pivot_table`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Total Sales\n",
      "region    state          city                      \n",
      "Northeast New York       New York          39801235\n",
      "West      California     San Francisco     33973228\n",
      "Southeast Florida        Miami             31600863\n",
      "          South Carolina Charleston        29285637\n",
      "          Florida        Orlando           27682851\n"
     ]
    }
   ],
   "source": [
    "# Show the total sales for the products sold for each region, state, and city.\n",
    "# Optional: Rename the \"total_sales\" column to \"Total Sales\"\n",
    "# Show the top 5 results.\n",
    "region_sales_pivot = sales_data.pivot_table(index=['region', 'state', 'city'], values='total_sales', aggfunc='sum')\n",
    "region_sales_pivot.rename(columns={'total_sales': 'Total Sales'}, inplace=True)\n",
    "print(region_sales_pivot.nlargest(5, 'Total Sales'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 4. Determine which Retailer had the Most Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `groupby`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        retailer     region           state           city  Total Sales\n",
      "103    West Gear       West      California  San Francisco     32794405\n",
      "50        Kohl's       West      California    Los Angeles     25127160\n",
      "22   Foot Locker  Northeast        New York       New York     25008568\n",
      "109    West Gear       West      Washington        Seattle     24862675\n",
      "33   Foot Locker  Southeast  South Carolina     Charleston     24822280\n"
     ]
    }
   ],
   "source": [
    "# Show the total sales for the products sold for each retailer, region, state, and city.\n",
    "# Rename the \"total_sales\" column to \"Total Sales\"\n",
    "# Show the top 5 results.\n",
    "retailer_sales = sales_data.groupby(['retailer', 'region', 'state', 'city'])['total_sales'].sum().reset_index()\n",
    "retailer_sales.rename(columns={'total_sales': 'Total Sales'}, inplace=True)\n",
    "print(retailer_sales.nlargest(5, 'Total Sales'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `pivot_table`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    Total Sales\n",
      "retailer    region    state          city                      \n",
      "West Gear   West      California     San Francisco     32794405\n",
      "Kohl's      West      California     Los Angeles       25127160\n",
      "Foot Locker Northeast New York       New York          25008568\n",
      "West Gear   West      Washington     Seattle           24862675\n",
      "Foot Locker Southeast South Carolina Charleston        24822280\n"
     ]
    }
   ],
   "source": [
    "# Show the total sales for the products sold for each retailer, region, state, and city.\n",
    "# Optional: Rename the \"total_sales\" column to \"Total Sales\"\n",
    "# Show the top 5 results.\n",
    "retailer_sales_pivot = sales_data.pivot_table(index=['retailer', 'region', 'state', 'city'], values='total_sales', aggfunc='sum')\n",
    "retailer_sales_pivot.rename(columns={'total_sales': 'Total Sales'}, inplace=True)\n",
    "print(retailer_sales_pivot.nlargest(5, 'Total Sales'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Determine which Retailer Sold the Most Women's Athletic Footwear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the sales data to get the women's athletic footwear sales data.\n",
    "women_footwear_sales = sales_data[sales_data['product'] == \"Women's Athletic Footwear\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `groupby`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          retailer     region           state           city  \\\n",
      "101      West Gear       West      California  San Francisco   \n",
      "22     Foot Locker  Northeast        New York       New York   \n",
      "49          Kohl's       West      California    Los Angeles   \n",
      "33     Foot Locker  Southeast  South Carolina     Charleston   \n",
      "68   Sports Direct      South           Texas         Dallas   \n",
      "\n",
      "     Womens_Footwear_Units_Sold  \n",
      "101                       12107  \n",
      "22                        10996  \n",
      "49                        10826  \n",
      "33                         8814  \n",
      "68                         8790  \n"
     ]
    }
   ],
   "source": [
    "# Show the total number of women's athletic footwear sold for each retailer, region, state, and city.\n",
    "# Rename the \"units_sold\" column to \"Womens_Footwear_Units_Sold\"\n",
    "# Show the top 5 results.\n",
    "women_footwear_retailer_sales = women_footwear_sales.groupby(['retailer', 'region', 'state', 'city'])['units_sold'].sum().reset_index()\n",
    "women_footwear_retailer_sales.rename(columns={'units_sold': 'Womens_Footwear_Units_Sold'}, inplace=True)\n",
    "print(women_footwear_retailer_sales.nlargest(5, 'Womens_Footwear_Units_Sold'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `pivot_table`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      Womens_Footwear_Units_Sold\n",
      "retailer      region    state          city                                     \n",
      "West Gear     West      California     San Francisco                       12107\n",
      "Foot Locker   Northeast New York       New York                            10996\n",
      "Kohl's        West      California     Los Angeles                         10826\n",
      "Foot Locker   Southeast South Carolina Charleston                           8814\n",
      "Sports Direct South     Texas          Dallas                               8790\n"
     ]
    }
   ],
   "source": [
    "# Show the total number of women's athletic footwear sold for each retailer, region, state, and city.\n",
    "# Rename the \"units_sold\" column to \"Womens_Footwear_Units_Sold\"\n",
    "# Show the top 5 results.\n",
    "women_footwear_retailer_sales_pivot = women_footwear_sales.pivot_table(index=['retailer', 'region', 'state', 'city'], values='units_sold', aggfunc='sum')\n",
    "women_footwear_retailer_sales_pivot.rename(columns={'units_sold': 'Womens_Footwear_Units_Sold'}, inplace=True)\n",
    "print(women_footwear_retailer_sales_pivot.nlargest(5, 'Womens_Footwear_Units_Sold'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Determine the Day with the Most Women's Athletic Footwear Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Total Sales\n",
      "invoice_date             \n",
      "1/10/21            315859\n",
      "1/11/2020          129556\n",
      "1/11/21             66584\n",
      "1/12/21            405693\n",
      "1/13/21            256764\n",
      "...                   ...\n",
      "9/6/21             103419\n",
      "9/7/21             241024\n",
      "9/8/2020           726106\n",
      "9/8/21             242278\n",
      "9/9/21             388630\n",
      "\n",
      "[355 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a pivot table with the 'invoice_date' column is the index, and the \"total_sales\" as the values.\n",
    "# Optional: Rename the \"total_sales\" column to \"Total Sales\"\n",
    "# Show the table.\n",
    "daily_sales = women_footwear_sales.pivot_table(index='invoice_date', values='total_sales', aggfunc='sum')\n",
    "daily_sales.rename(columns={'total_sales': 'Total Sales'}, inplace=True)\n",
    "print(daily_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (4254969456.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[32], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    sorted_Total_Sales = daily_sales_resampled.sort_values(by='Total Sales', ascending=False))\u001b[0m\n\u001b[0m                                                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "# Resample the pivot table into daily bins, and get the total sales for each day.\n",
    "# Sort the resampled pivot table in ascending order on \"Total Sales\".\n",
    "daily_sales_resampled = daily_sales.resample('D').sum()\n",
    "print(daily_sales_resampled.sort_values(by='Total Sales', ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.  Determine the Week with the Most Women's Athletic Footwear Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/calvarez/Downloads/athletic_sales_analysis_starter_code_updated.ipynb Cell 40\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/calvarez/Downloads/athletic_sales_analysis_starter_code_updated.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Resample the pivot table into weekly bins, and get the total sales for each week.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/calvarez/Downloads/athletic_sales_analysis_starter_code_updated.ipynb#X54sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# Sort the resampled pivot table in ascending order on \"Total Sales\".\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/calvarez/Downloads/athletic_sales_analysis_starter_code_updated.ipynb#X54sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m weekly_sales_resampled \u001b[39m=\u001b[39m daily_sales\u001b[39m.\u001b[39;49mresample(\u001b[39m'\u001b[39;49m\u001b[39mW\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39msum()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/calvarez/Downloads/athletic_sales_analysis_starter_code_updated.ipynb#X54sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(weekly_sales_resampled\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTotal Sales\u001b[39m\u001b[39m'\u001b[39m, ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py:9439\u001b[0m, in \u001b[0;36mNDFrame.resample\u001b[0;34m(self, rule, axis, closed, label, convention, kind, on, level, origin, offset, group_keys)\u001b[0m\n\u001b[1;32m   9436\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   9437\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 9439\u001b[0m \u001b[39mreturn\u001b[39;00m get_resampler(\n\u001b[1;32m   9440\u001b[0m     cast(\u001b[39m\"\u001b[39;49m\u001b[39mSeries | DataFrame\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mself\u001b[39;49m),\n\u001b[1;32m   9441\u001b[0m     freq\u001b[39m=\u001b[39;49mrule,\n\u001b[1;32m   9442\u001b[0m     label\u001b[39m=\u001b[39;49mlabel,\n\u001b[1;32m   9443\u001b[0m     closed\u001b[39m=\u001b[39;49mclosed,\n\u001b[1;32m   9444\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   9445\u001b[0m     kind\u001b[39m=\u001b[39;49mkind,\n\u001b[1;32m   9446\u001b[0m     convention\u001b[39m=\u001b[39;49mconvention,\n\u001b[1;32m   9447\u001b[0m     key\u001b[39m=\u001b[39;49mon,\n\u001b[1;32m   9448\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   9449\u001b[0m     origin\u001b[39m=\u001b[39;49morigin,\n\u001b[1;32m   9450\u001b[0m     offset\u001b[39m=\u001b[39;49moffset,\n\u001b[1;32m   9451\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[1;32m   9452\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/resample.py:1970\u001b[0m, in \u001b[0;36mget_resampler\u001b[0;34m(obj, kind, **kwds)\u001b[0m\n\u001b[1;32m   1966\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1967\u001b[0m \u001b[39mCreate a TimeGrouper and return our resampler.\u001b[39;00m\n\u001b[1;32m   1968\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1969\u001b[0m tg \u001b[39m=\u001b[39m TimeGrouper(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m-> 1970\u001b[0m \u001b[39mreturn\u001b[39;00m tg\u001b[39m.\u001b[39;49m_get_resampler(obj, kind\u001b[39m=\u001b[39;49mkind)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/resample.py:2160\u001b[0m, in \u001b[0;36mTimeGrouper._get_resampler\u001b[0;34m(self, obj, kind)\u001b[0m\n\u001b[1;32m   2151\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(ax, TimedeltaIndex):\n\u001b[1;32m   2152\u001b[0m     \u001b[39mreturn\u001b[39;00m TimedeltaIndexResampler(\n\u001b[1;32m   2153\u001b[0m         obj,\n\u001b[1;32m   2154\u001b[0m         timegrouper\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2157\u001b[0m         gpr_index\u001b[39m=\u001b[39max,\n\u001b[1;32m   2158\u001b[0m     )\n\u001b[0;32m-> 2160\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   2161\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mOnly valid with DatetimeIndex, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2162\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mTimedeltaIndex or PeriodIndex, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2163\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got an instance of \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(ax)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2164\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'"
     ]
    }
   ],
   "source": [
    "# Resample the pivot table into weekly bins, and get the total sales for each week.\n",
    "# Sort the resampled pivot table in ascending order on \"Total Sales\".\n",
    "weekly_sales_resampled = daily_sales.resample('W').sum()\n",
    "print(weekly_sales_resampled.sort_values(by='Total Sales', ascending=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
